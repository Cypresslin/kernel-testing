#!/usr/bin/env python3
#
# kmsgq-jenkins
#   An app that listens for RabbitMQ messages related to kernel testing requests
#   and processes them.
#
#   This app is multithreaded. The messages are taken from the message queue and
#   put a queue for the thread to then processes. This is done because it may be
#   necessary to send messages to the message queue as part of the processing and
#   that can't be done in the same context as the msgq handler.
#

import sys
sys.path.insert(0, 'lib3')
from os                                 import path
from time                               import sleep
import re
import copy
from argparse                           import ArgumentParser, RawDescriptionHelpFormatter
from logging                            import basicConfig, DEBUG, INFO, WARNING
import signal
import traceback
import json
import threading
import queue
from datetime                           import datetime
from lib.log                            import center, cleave, Clog, cinfo, cdebug
from lib.testsprops                     import SRU_TestsList, LKP_TestsList, BOOT_TestsList, LivepatchSnappyClientPayloadTests
from lib3.msgq                          import MsgQueue
from mako.template                      import Template
from mako.exceptions                    import RichTraceback
from lib3.jenkins_server_local          import JenkinsServerLocal
from lib.ubuntu                         import Ubuntu

# Exit
#
class Exit(Exception):
    """
    If an error message has already been displayed and we want to just exit the app, this
    exception is raised.
    """
    pass

# JobsFactory
#
class JobsFactory(object):
    # __init__
    #
    def __init__(s, request, cfg):
        s.jenkins = JenkinsServerLocal.connect()
        s.jd = {
            'who'            : None,
            'op'             : 'bogus',
            'date'           : '1960.11.02_08.00.00',
            'ppa'            : None,
            'url'            : None,
            'decoration'     : None,
            'kernel-version' : None,
            'package'        : None,
            'pkg-name'       : None,
            'lkp'            : False
        }
        # Anything / everything in the payload overrides the defaults.
        #
        for k in request:
            s.jd[k] = request[k]    # Generated by the request, copied as is.

        # Create a new key: pkg-name for HWE / lts kernel here by using
        # 'package' passed from the json request
        # Package naming is different between lts and hwe kernel
        # e.g. linux-generic-lts-xenial / linux-generic-hwe-16.04-edge
        if '~' in s.jd['kernel-version']:
            # Insert the flavour
            s.jd['pkg-name'] = 'linux-' + s.jd['package'].replace('linux', s.jd['flavour'])
            # Insert the version number for HWE package
            if 'hwe' in s.jd['package']:
                series_ver = s.jd['kernel-version'].split('~')[1]
                series_ver = re.match('\d+\.\d+', series_ver).group(0)
                s.jd['pkg-name'] = s.jd['pkg-name'].replace('hwe', 'hwe-' + series_ver)

        s.dbg = False
        s._configuration = None
        s._sut_pool = None
        s.cfg = cfg

        if cfg.lkp:
            s.system_class = 'live'
            s.job_template = s.load_template('standard-jenkins-test-job.mako')
        elif cfg.dev:
            s.system_class = 'test-development'
            s.job_template = s.load_template('dev-jenkins-test-job.mako')
        else:
            s.system_class = 'sru-testing'
            s.job_template = s.load_template('standard-jenkins-test-job.mako')


    # date_to_string
    #
    def date_to_string(s, date):
        """
        Return a standard, string representation of the date given. It is assumed that the
        date is UTC based.
        """
        return "None" if date is None else date.strftime("%A, %d. %B %Y %H:%M UTC")

    # configuration
    #
    @property
    def configuration(s):
        '''
        There are some things that need to be more dynamic. Changes to
        lib/configuration.py or the standard-jenkins-test-job.mako files
        shouldn't require killing the running kmsgq-jenkins job.
        '''
        if s._configuration is None:
            import lib.configuration
            s._configuration = lib.configuration.Configuration

        return s._configuration

    # sut_pool
    #
    @property
    def sut_pool(s):
        '''
        '''
        if s._sut_pool is None:
            # Create a dictionary of the lab HW keyed by role.
            #
            s._sut_pool = {}
            for sut in s.configuration['systems']:
                try:
                    if s.configuration['systems'][sut]['class'] == s.system_class:
                        for role in s.configuration['systems'][sut]['role']:
                            try:
                                s._sut_pool[role].append(sut)
                            except:
                                s._sut_pool[role] = []
                                s._sut_pool[role].append(sut)
                except TypeError:
                    print('s.configuration[\'systems\'][sut][\'role\'] missing for %s' % sut)
                    raise
                except KeyError:
                    pass

        return s._sut_pool

    # determine_tests
    #
    def determine_tests(s):
        '''
        The request['op'] determines which group of tests are to be run.
        '''
        center(s.__class__.__name__ + '.determine_tests')

        if 'sru' == s.jd['op']:
            s.jd['tests'] = SRU_TestsList
            if 'priority' not in s.jd:
                s.jd['priority'] = 3
        elif 'boot' == s.jd['op']:
            s.jd['tests'] = BOOT_TestsList
            if 'priority' not in s.jd:
                s.jd['priority'] = 4
        elif s.cfg.lkp:
            s.jd['tests'] = LKP_TestsList
            if 'priority' not in s.jd:
                s.jd['priority'] = 3
        else:
            s.jd['tests'] = ['default']
            if 'priority' not in s.jd:
                s.jd['priority'] = 3

        cleave(s.__class__.__name__ + '.determine_tests')

    # determine_systems
    #
    def determine_systems(s):
        '''
        Based on the tests that are to be run, determine which hosts are targeted
        to run those tests.
        '''
        center(s.__class__.__name__ + '.determine_systems')
        s.jd['systems'] = []
        for t in s.jd['tests']:
            for system in s.valid_systems(t, s.jd['series-name']):
                if system not in s.jd['systems']:
                    s.jd['systems'].append(system)
                    cdebug('appending : %s' % system)
        cleave(s.__class__.__name__ + '.determine_systems')

    # determine_arches
    #
    def determine_arches(s):
        '''
        Based on the systems to be used for testing, determine which arches they
        support. Some hosts support multiple arches (amd64 & i386 for example).
        '''
        center(s.__class__.__name__ + '.determine_arches')
        s.jd['arches'] = []
        for system in s.jd['systems']:
            for a in s.configuration['systems'][system]['arch']:
                if a not in s.jd['arches']:
                    s.jd['arches'].append(a)
                    cdebug('appending : %s' % a)
        cleave(s.__class__.__name__ + '.determine_arches')

    # valid_systems
    #
    def valid_systems(s, key, series):
        '''
        Check if the SUT is blacked listed for the desired release. Or if it's
        hwe kernel (which has a '~' in kernel version) for s390x, as we can't
        re-deploy s390x systems with MaaS now.
        '''
        retval = []
        try:
            for system in s.sut_pool[key]:
                try:
                    if series in s.configuration['systems'][system]['series-blacklist']:
                        continue
                    elif '~' in s.jd['kernel-version']:
                        arch = ','.join(s.configuration['systems'][system]['arch'])
                        if 's390x' in arch:
                            continue
                except KeyError:
                    pass
                retval.append(system)
        except KeyError:
            pass
        return retval

    # create_jobs
    #
    def create_jobs(s):
        if 'tests' not in s.jd:
            s.determine_tests()

        if 'systems' not in s.jd:
            s.determine_systems()

        if 'arches' not in s.jd:
            s.determine_arches()

        if Clog.dbg:
            cdebug('tests: [')
            for test in s.jd['tests']:
                cdebug("    '%s'," % test)
            cdebug(']')

            cdebug('systems: [')
            for system in s.jd['systems']:
                cdebug("    '%s'," % system)
            cdebug(']')

            cdebug('arches: [')
            for arch in s.jd['arches']:
                cdebug("    '%s'," % arch)
            cdebug(']')

        s.from_tests_generate_jobs(s.jd)

    # from_tests_generate_jobs
    #
    def from_tests_generate_jobs(s, jd):
        center('TheApp::from_tests_generate_jobs')

        jd['jobs'] = []

        for test in jd['tests']:
            cdebug('test: %s' % test, 'blue')

            # Note: jd['systems'] should never be empty when we get here. If it is then _handler isn't doing
            #       it's job.

            try:
                jd = s.generate_jobs(test, s.valid_systems(test, jd['series-name']), jd)
                # jd = s.generate_jobs(test, jd['systems'], jd)
            except KeyError:
                cdebug('KeyError Exception for %s' % test)

        cleave('TheApp::from_tests_generate_jobs')

    # generate_jobs
    #
    def generate_jobs(s, test, systems, jd):
        """
        Generate test cases for the corresponding arches in the test pool.
        """
        center('TheApp::generate_jobs')

        for system in systems:
            cdebug('system: %s' % system, 'blue')
            for arch in jd['arches']:
                if arch in s.configuration['systems'][system]['arch']:
                    cdebug('arch: %s' % arch, 'blue')
                    job = s.generate_individual_job(test, arch, system, jd)

        cleave('TheApp::generate_jobs')
        return jd

    # load_template
    #
    def load_template(self, file_name):
        """
        Load the template file.
        """
        center('TheApp::load_template')
        retval = None

        if file_name[0] == '/' or file_name[0] == '.':
            # The full path is specified. Use the name as is.
            #
            fid = file_name
        else:
            # Find it ...
            #
            fid = file_name
            if not path.exists(fid):  # Current directory
                fid = path.join(path.dirname(sys.argv[0]), file_name)
                if not path.exists(fid):
                    fid = None

        if fid is not None:
            with open(fid, 'r') as f:
                retval = Template(f.read())
        else:
            print("Error: Failed to find the template file.")

        cleave('TheApp::load_template')
        return retval

    # generate_individual_job
    #
    def generate_individual_job(s, test, arch, system, jd):
        center('TheApp::generate_individual_job')

        job_data = copy.deepcopy(jd)
        job_name = s.job_name(job_data, arch, system, test)

        job_data['job-name'] = job_name
        job_data['sut-arch'] = arch
        job_data['sut-name'] = system
        job_data['test']     = test
        job_data['description'] = json.dumps(job_data, sort_keys=True, indent=4)
        job_data['timestamp'] = s.date_to_string(datetime.utcnow())

        try:
            job_xml = s.job_template.render(data=job_data)

            with open('/tmp/jenkins.xml', 'w') as f:
                f.write(job_xml)

        except:
            traceback = RichTraceback()
            for (filename, lineno, function, line) in traceback.traceback:
                print("File %s, line %s, in %s" % (filename, lineno, function))
                for s in line:
                    sys.stdout.write(s)
            print("%s: %s" % (str(traceback.error.__class__.__name__), traceback.error))
            raise

        try:
            s.jenkins.delete_job(job_name)
        except:
            pass

        s.jenkins.create_job(job_name, job_xml)
        sleep(2)
        s.jenkins.build_job(job_name)
        cdebug('created jenkins job: %s' % job_name)
        cleave('TheApp::generate_individual_job')
        return job_data

    # job_name
    #
    def job_name(s, jd, arch, system, tests):
        center('TheApp::job_name')
        retval = ""

        # The job name starts with some form of the test name(s)
        #
        cdebug('tests: %s (%s)' % (tests, type(tests)))
        if isinstance(tests, str) or isinstance(tests, unicode):
            retval += tests
            retval += '__'
        else:
            retval += '-'.join(tests)
            retval = retval.replace('ubuntu', 'u')
            retval += '__'

        if s.cfg.lkp:
            retval += jd['package']
            if '~' in s.jd['kernel-version']:
                retval += '-hwe'
        else:
            retval += jd['series-name'].title()[0]  # Only want the first character
            retval += jd['package'].replace('linux','')

        if 'series-decoration' in jd and jd['series-decoration'] is not None:
            retval += '_%s' % jd['series-decoration']

        if 'flavour' in jd:
            retval += '_%s-%s__using_%s' % (arch, jd['flavour'], system)
        else:
            retval += '_%s__using_%s' % (arch, system)

        if jd['who'] is not None:
            retval += '__for_%s' % '_'.join(jd['who'])

        cdebug('job name: %s' % (retval))
        cleave('TheApp::job_name')
        return retval

class RequestHandler(threading.Thread):

    # __init__
    #
    def __init__(s, cmd_q=queue.Queue(), reply_q=queue.Queue(), cfg={}, msgq=None):
        threading.Thread.__init__(s)
        s.cmd_q = cmd_q
        s.reply_q = reply_q
        s.msgq = msgq
        s.alive = threading.Event()
        s.alive.set()
        s.cfg = cfg

    # handle_request
    #
    def handle(s, request):
        center(s.__class__.__name__ + '.handle')
        cinfo('        ---------------------------------------  h a n d l e  ---------------------------------------', 'green')
        cinfo(json.dumps(request, sort_keys=True, indent=4))

        request['lkp'] = s.cfg.lkp
        if request['key'] == 'kernel.publish':
            request['series-decoration'] = 'SRU'
            request['who'] = None

        jf = JobsFactory(request, s.cfg)
        jf.create_jobs()

        cleave(s.__class__.__name__ + '.handle')

    # dequeue
    #
    def dequeue(s):
        # bjf center(s.__class__.__name__ + '.dequeue')
        try:
            # Queue.get with timeout to allow checking s.alive
            request = s.cmd_q.get(True, 0.1)
            s.handle(request)

        except queue.Empty:
            pass
        # bjf cleave(s.__class__.__name__ + '.dequeue')

    # run
    #
    def run(s):
        center(s.__class__.__name__ + '.run')
        while s.alive.isSet():
            s.dequeue()
            sleep(10)
        cleave(s.__class__.__name__ + '.run')


# Jobber
#
class Jobber(object):
    '''
    '''

    # __init__
    #
    def __init__(s):
        '''
        '''
        center(s.__class__.__name__ + '.__init__')
        cleave(s.__class__.__name__ + '.__init__')

    # sigterm_handler
    #
    def sigterm_handler(s, signu, frame):
        center(s.__class__.__name__ + '.sigterm_handler')
        raise Exit()
        cleave(s.__class__.__name__ + '.sigterm_handler')

    # sighup_handler
    #
    def sighup_handler(s, signu, frame):
        center(s.__class__.__name__ + '.sighup_handler')
        cleave(s.__class__.__name__ + '.sighup_handler')

    # enqueue
    #
    def enqueue(s, payload):
        center(s.__class__.__name__ + '.enqueue')
        s.rh.cmd_q.put(payload)
        cleave(s.__class__.__name__ + '.enqueue')

    # valid_pkgs
    #
    @property
    def valid_pkgs(s):
        retval = ['linux', 'linux-fips']

        db = Ubuntu().db
        for k in db:
            if 'backport-packages' in db[k]:
                for bp in db[k]['backport-packages']:
                    if bp not in ['linux-azure', 'linux-azure-edge', 'linux-gke', 'linux-aws', 'linux-gcp']:
                        retval.append(bp)
        return retval

    # msgq_handler
    #
    def msgq_handler(s, payload):
        center(s.__class__.__name__ + '.msgq_handler')

        # Based on command line options we support different keys
        #
        if s.args.lkp:
            valid_keys = ['kernel.testing.livekernelpatching.request', 'livepatch.publish']
        elif s.args.dev:
            valid_keys = ['kdev.testing.request', 'kdev.testing.livekernelpatching.request']
        else:
            valid_keys = ['kernel.testing.request', 'kernel.publish', 'kernel.testing.job']

        valid_ops  = ['sru', 'boot']
        if s.args.lkp:
            valid_ops.append('livepatch-regression-test')
            valid_ops.append('livepatch-snappy-client-payload-test')

        try:
            # Determine if the key in the current message is on that
            # we are going to process.
            #
            for key in valid_keys:
                if not payload['key'].startswith(key):
                    cdebug('Invalid key: %s' % payload['key'])
                    continue

                if payload['op'] not in valid_ops:
                    cdebug('Invalid op: %s' % payload['op'])
                    continue

                if s.args.lkp:
                    if not payload['package'].startswith('livepatch'):
                        cdebug('Invalid package: %s' % payload['package'])
                        continue
                else:
                    if payload['package'] not in s.valid_pkgs:
                        cdebug('Invalid package: %s' % payload['package'])
                        continue

                # Just assume the 'generic' flavour is nothing is specified
                if s.args.lkp:
                    if 'flavour' not in payload:
                        payload['flavour'] = 'generic'
                s.enqueue(payload)
                break
        except KeyError:
            # Bad payload
            #
            sys.stderr.write('  ** Invalid payload:\n')
            sys.stderr.write(json.dumps(payload, sort_keys=True, indent=4))
            sys.stderr.write('\n\n')

        cleave(s.__class__.__name__ + '.msgq_handler')

    # main
    #
    def main(s, args):
        center(s.__class__.__name__ + '.main')
        retval = 0
        s.args = args

        signal.signal(signal.SIGTERM, s.sigterm_handler)
        signal.signal(signal.SIGHUP,  s.sighup_handler)

        try:
            mq = MsgQueue()
            if args.lkp:
                queue = 'livepatch-monitor'
                key = 'livepatch.#'
            elif args.dev:
                queue = 'kdev-publishing-monitor'
                key = 'kdev.#'
            else:
                queue = 'kernel-publishing-monitor'
                key = 'kernel.#'

            cfg = type('Config', (object,), {})
            setattr(cfg, 'dev', args.dev)
            setattr(cfg, 'lkp', args.lkp)

            s.rh = RequestHandler(msgq=mq, cfg=cfg)
            s.rh.start()

            # mq.queue_delete(queue)
            mq.listen(queue, key, s.msgq_handler)

            retval = 0

        # Handle the user presses <ctrl-C>.
        #
        except KeyboardInterrupt:
            print("Aborting ...")
            s.rh.alive.clear()

        except Exit:
            print("")
            print("Due to the above error(s), this script is unable to continue and is terminating.")
            print("")
            s.rh.alive.clear()

        cleave(s.__class__.__name__ + '.main (%s)' % retval)
        return retval

if __name__ == '__main__':
    retval = -1

    # Command line argument setup and initial processing
    #
    app_description = '''
    '''
    app_epilog = '''
    '''
    parser = ArgumentParser(description=app_description, epilog=app_epilog, formatter_class=RawDescriptionHelpFormatter)
    parser.add_argument('--debug', action='store_true', default=False, help='')
    parser.add_argument('--info',  action='store_true', default=False, help='')
    parser.add_argument('--lkp',   action='store_true', default=False, help='Handle requests for live kernel patching testing.')
    parser.add_argument('--dev',   action='store_true', default=False, help='Handle development testing requests.')

    args = parser.parse_args()

    # If logging parameters were set on the command line, handle them
    # here.
    #
    Clog.color = True
    if args.debug:
        log_format = "%(levelname)s - %(message)s"
        basicConfig(level=DEBUG, format=log_format)
        Clog.dbg = True
    elif args.info:
        log_format = "%(message)s"
        basicConfig(level=INFO, format=log_format)
    else:
        log_format = "%(message)s"
        basicConfig(level=WARNING, format=log_format)

    center('__main__')
    try:
        app = Jobber()
        retval = app.main(args)
    except KeyboardInterrupt:
        pass
    except Exception:
        trace = traceback.format_exc()
        try:
            sys.stderr.write(trace)
        except:
            pass
        logfile = open(path.join('.', 'exceptions.log'), 'a')
        logfile.write('Critical exception in %s' % sys.argv[0])
        logfile.write(trace)
        logfile.write('----------------------------------------\n\n')
        logfile.close()

    cleave('__main__ (%s)' % (retval))
    exit(retval)

# vi:set ts=4 sw=4 expandtab syntax=python:
