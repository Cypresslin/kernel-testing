#!/usr/bin/env python
#
# This application takes a list json file as input. That json file
# contains a 'dictionary' of key value pairs where the key is a
# LauncPad bug id and the value is the source package of interest.
#

from sys                                import argv, stderr
from getopt                             import getopt, GetoptError
from os                                 import listdir
from json                               import dumps

from lib.core.utils                     import stdo, error, json_load
from lib.core.dbg                       import Dbg


# CmdlineError
#
# The type of exception that will be raised by Cmdline.process() if there
# are command line processing errors.
#
class CmdlineError(Exception):
    # __init__
    #
    def __init__(self, error):
        self.msg = error

# Cmdline
#
class Cmdline:
    """
    Handle all the command line processing for the application.
    """
    # error
    #
    def error(self, e, defaults):
        """
        Simple helper which prints out an error message and then prints out the usage.
        """
        if e != '': error("%s\n" % e)
        self.usage(defaults)

    # usage
    #
    def usage(self, defaults):
        """
        Prints out the help text which explains the command line options.
        """
        stdo("    Usage:                                                                                   \n")
        stdo("        %s [<options>] datafile1 datafile2 . . .                                             \n" % defaults['app_name'])
        stdo("                                                                                             \n")
        stdo("    Options:                                                                                 \n")
        stdo("        --help           Prints this text.                                                   \n")
        stdo("                                                                                             \n")
        stdo("        --verbose        Give some feedback of what is happening while the script is         \n")
        stdo("                         running.                                                            \n")
        stdo("                                                                                             \n")
        stdo("        --debug=<debug options>                                                              \n")
        stdo("                         Performs additional output related to the option enabled and        \n")
        stdo("                         the application defined support for the option.                     \n")
        stdo("                                                                                             \n")
        stdo("                         Recognized debug options:                                           \n")
        stdo("                             enter                                                           \n")
        stdo("                             leave                                                           \n")
        stdo("                             verbose                                                         \n")
        stdo("                             cfg                                                             \n")
        stdo("                                                                                             \n")
        stdo("        --job-name=<string>  Filter data, only including files with the JOB_NAME equal to    \n")
        stdo("                         the specified string.                                               \n")
        stdo("                                                                                             \n")
        stdo("        --kernel-version=<list>  Filter data, only including files with the kernel versions  \n")
        stdo("                         equal to the specified strings (comma-delimited).                   \n")
        stdo("                                                                                             \n")
        stdo("        --chart-title=<string>  REQUIRED Use this title for the graphical chart from this    \n")
        stdo("                         data                                                                \n")
        stdo("                                                                                             \n")
        stdo("        --baseline=<json file name>  Normalize all results to the values in this file        \n")
        stdo("                                                                                             \n")
        stdo("        --mute-metrics=<comma delimited list> Do not display the listed metrics              \n")
        stdo("                                                                                             \n")
        stdo("        --only-metrics=<comma delimited list> Only display the listed metrics                \n")
        stdo("                                                                                             \n")
        stdo("    Examples:                                                                                \n")
        stdo("        %s --debug=\"enter,leave,verbose\"                                                   \n" % defaults['app_name'])

    # process
    #
    def process(self, argv, defaults):
        """
        This method is responsible for calling the getopt function to process the command
        line. All parameters are processed into class variables for use by other methods.
        """
        result = True
        try:
            cfg = defaults

            optsShort = ''
            optsLong  = ['help', 'verbose', 'debug=', 'job-name=', 'kernel-version=', 'baseline=', 'mute-metrics=', 'only-metrics=', 'chart-title=']
            opts, args = getopt(argv[1:], optsShort, optsLong)

            for opt, val in opts:
                if (opt == '--help'):
                    raise CmdlineError('')

                elif (opt == '--verbose'):
                    cfg['verbose'] = True
                    if 'verbose' not in Dbg.levels:
                        Dbg.levels.append('verbose')

                elif (opt == '--job-name'):
                    cfg['job-name'] = val

                elif (opt == '--kernel-version'):
                    cfg['kernel-versions'] = val.split(",")

                elif (opt == '--baseline'):
                    cfg['baseline'] = val

                elif (opt == '--chart-title'):
                    cfg['chart-title'] = val

                elif (opt == '--mute-metrics'):
                    cfg['mute'] = val.split(',')

                elif (opt == '--only-metrics'):
                    if 'mute' in cfg:
                        raise CmdlineError("You can't use both --mute-metrics and --only-metrics")
                    cfg['only'] = val.split(',')

                elif opt in ('--debug'):
                    cfg['debug'] = val.split(',')
                    for level in cfg['debug']:
                        if level not in Dbg.levels:
                            Dbg.levels.append(level)

            if len(args) < 1:
                raise CmdlineError('You must supply at least one benchmark data file to process')

            if 'chart-title' not in cfg:
                raise CmdlineError('You must supply a chart title')

            cfg['datafiles'] = args

        except GetoptError, error:
            raise CmdlineError(error)

        return cfg


# Exit
#
class Exit():
    """
    If an error message has already been displayed and we want to just exit the app, this
    exception is raised.
    """
    pass

# MergeBenchmarkData
#
class MergeBenchmarkData():
    """

    """

    # __init__
    #
    def __init__(self, cfg):
        Dbg.enter("MergeBenchmarkData.__init__")
        self.cfg    = cfg
        self.tests = {}

        Dbg.leave("MergeBenchmarkData.__init__")

    # initialize
    #
    def initialize(self):
        """
        A separate initialize that we can control when it gets called (not
        when the object is instantiated).
        """
        Dbg.enter("MergeBenchmarkData.initialize")

        return

    # get_from_meta
    # This is needed to deal with both old and new data file formats
    def get_from_meta(self, metadict, key):
        if key in metadict:
            return metadict[key]
        elif key in metadict['environ']:
            return metadict['environ'][key]
        else:
            raise KeyError("Can't find metadata key %s in data file" % key)

    # main
    #
    def main(self):
        Dbg.enter("MergeBenchmarkData.main")

        try:
            self.initialize()

            if 'baseline' in self.cfg:
                # we load the baseline numbers, and scale all results to that
                baseline = json_load(self.cfg['baseline'])
                if 'job-name' in self.cfg:
                    jobname = self.get_from_meta(baseline['meta'], 'JOB_NAME')
                    if self.cfg['job-name'] != jobname:
                        print >>stderr,"ERROR: The job name in the baseline file does not match the specified job name"
                        raise ValueError

                # apply the same filtering that we will for the metrics
                mkeys = baseline['metrics'].keys()
                if 'only' in self.cfg:
                    for metric in mkeys:
                        if metric not in self.cfg['only']:
                            del baseline['metrics'][metric]
                elif 'mute' in self.cfg:
                    for metric in mkeys:
                        if metric in self.cfg['mute']:
                            del baseline['metrics'][metric]

                # Now, find the highest value among all the request metrics so we can scale to that
                norm_val = None
                mkeys = baseline['metrics'].keys()
                for metric in mkeys:
                    #print('%s : %s' % (metric, baseline['metrics'][metric]))
                    if norm_val is None:
                        norm_val =  float(baseline['metrics'][metric])
                    elif  (float(baseline['metrics'][metric]) > norm_val):
                        norm_val =  float(baseline['metrics'][metric])

            # Open each file on the command line and process it
            for fname in self.cfg['datafiles']:
                data = json_load(fname)

                # use only the kernel name specified
                if 'kernel-versions' in self.cfg:
                    # a hack to deal with older style data files
                    if 'kernel' in data['meta']:
                        kver = data['meta']['kernel']
                    elif 'sysinfo-uname' in data['meta']:
                        # older style
                        kver =  data['meta']['sysinfo-uname'].split()[0]
                    else:
                        raise ValueError("Could not find kernel version in metadata")
                    #print >>stderr, "KVER = %s" % kver
                    # we take this data file if the kernel is in our list
                    kernelmatch = False
                    for wanted_version in self.cfg['kernel-versions']:
                        #print >>stderr,"COMPARING kernel version %s" % wanted_version
                        if wanted_version in kver:
                            kernelmatch = True

                    if not kernelmatch:
                        continue

                # use only the job name specified
                if 'job-name' in self.cfg:
                    jobname = self.get_from_meta(data['meta'], 'JOB_NAME')
                    if self.cfg['job-name'] != jobname:
                        continue
                # filter metrics as requested
                mkeys = data['metrics'].keys()
                if 'only' in self.cfg:
                    for metric in mkeys:
                        if metric not in self.cfg['only']:
                            del data['metrics'][metric]
                elif 'mute' in self.cfg:
                    for metric in mkeys:
                        if metric in self.cfg['mute']:
                            del data['metrics'][metric]

                # if we're scaling to a baseline, do it
                if 'baseline' in self.cfg:
                    mkeys = data['metrics'].keys()
                    for metric in mkeys:
                        mval = float(data['metrics'][metric])/norm_val
                        data['metrics'][metric] = '%s' % mval

                # Add the chart name to the metadata
                # It's added to each test in a collection, but they all use the same one
                data['meta']['chart-title'] = self.cfg['chart-title']

                # Save this test, as the BUILD_ID string, which can be sorted chronologically
                buildid = self.get_from_meta(data['meta'], 'BUILD_ID')
                self.tests[buildid] = data

            # now that we're done
            if len(self.tests) == 0:
                raise ValueError("There are no data records to write to the output file")
            print dumps(self.tests, sort_keys=True, indent=4)

        # Handle the user presses <ctrl-C>.
        #
        except KeyboardInterrupt:
            pass

        except Exit:
            pass

        Dbg.leave("MergeBenchmarkData.main")
        return

if __name__ == '__main__':
    defaults = {}
    defaults['app_name'] = argv[0]

    # The cmdline processing is done here partially so the debug options
    # can be processed right away.
    #
    cmdline = Cmdline()
    try:
        app = MergeBenchmarkData(cmdline.process(argv, defaults))
        app.main()
    except CmdlineError as e:
        cmdline.error(e.msg, defaults)

# vi:set ts=4 sw=4 expandtab:

