#!/usr/bin/env python3
#
# kmsgq-jenkins
#   An app that listens for RabbitMQ messages related to kernel testing requests
#   and processes them.
#
#   This app is multithreaded. The messages are taken from the message queue and
#   put a queue for the thread to then processes. This is done because it may be
#   necessary to send messages to the message queue as part of the processing and
#   that can't be done in the same context as the msgq handler.
#

from sys                                import stderr, argv
from os                                 import path
from time                               import sleep
import copy
from argparse                           import ArgumentParser, RawDescriptionHelpFormatter
from logging                            import basicConfig, DEBUG, INFO, WARNING
import signal
import traceback
import json
import threading
import queue
from lib.log                            import center, cleave, Clog, cinfo, cdebug
from lib3.msgq                          import MsgQueue
from lib.jenkins                        import Jenkins
from lib.testsprops                     import SRU_TestsList, LKP_TestsList, BOOT_TestsList

# Exit
#
class Exit():
    """
    If an error message has already been displayed and we want to just exit the app, this
    exception is raised.
    """
    pass

# JobsCreator
#
class JobsCreator():
    # __init__
    #
    def __init__(s, request):
        s.jenkins = Jenkins("http://localhost:8080")
        s.jd = copy.deepcopy(request)  # Job Description (jd)
        s.dbg = False
        s._configuration = None
        s._sut_pool = None

    # configuration
    #
    @property
    def configuration(s):
        '''
        There are some things that need to be more dynamic. Changes to
        lib/configuration.py or the standard-jenkins-test-job.mako files
        shouldn't require killing the running kmsgq-jenkins job.
        '''
        if s._configuration is None:
            import lib.configuration
            s._configuration = lib.configuration.Configuration

        return s._configuration

    # sut_pool
    #
    @property
    def sut_pool(s):
        '''
        '''
        if s._sut_pool is None:
            # Create a dictionary of the lab HW keyed by role.
            #
            s._sut_pool = {}
            for sut in s.configuration['systems']:
                try:
                    for role in s.configuration['systems'][sut]['role']:
                        try:
                            s._sut_pool[role].append(sut)
                        except:
                            s._sut_pool[role] = []
                            s._sut_pool[role].append(sut)
                except TypeError:
                    print('s._configuration[\'systems\'][sut][\'role\'] missing for %s' % sut)
                    raise

        return s._sut_pool

    # determine_tests
    #
    def determine_tests(s):
        '''
        The request['op'] determines which group of tests are to be run.
        '''
        center(s.__class__.__name__ + '.determine_tests')

        if 'sru' == s.jd['op']:
            s.jd['tests'] = SRU_TestsList
        elif 'boot' == s.jd['op']:
            s.jd['tests'] = BOOT_TestsList
        elif s.args.lkp:
            s.jd['tests'] = LKP_TestsList
        else:
            s.jd['tests'] = ['default']

        cleave(s.__class__.__name__ + '.determine_tests')

    # determine_systems
    #
    def determine_systems(s):
        '''
        Based on the tests that are to be run, determine which hosts are targeted
        to run those tests.
        '''
        center(s.__class__.__name__ + '.determine_systems')
        s.jd['systems'] = []
        for t in s.jd['tests']:
            for system in s.valid_systems(t, s.jd['series-name']):
                if system not in s.jd['systems']:
                    s.jd['systems'].append(system)
                    cdebug('appending : %s' % system)
        cleave(s.__class__.__name__ + '.determine_systems')

    # determine_arches
    #
    def determine_arches(s):
        '''
        Based on the systems to be used for testing, determine which arches they
        support. Some hosts support multiple arches (amd64 & i386 for example).
        '''
        center(s.__class__.__name__ + '.determine_arches')
        s.jd['arches'] = []
        for system in s.jd['systems']:
            for a in s.configuration['systems'][system]['arch']:
                if a not in s.jd['arches']:
                    s.jd['arches'].append(a)
                    cdebug('appending : %s' % a)
        cleave(s.__class__.__name__ + '.determine_arches')

    # valid_systems
    #
    def valid_systems(s, key, series):
        retval = []
        try:
            for system in s.sut_pool[key]:
                try:
                    if series in s.configuration['systems'][system]['series-blacklist']:
                        continue
                except KeyError:
                    pass
                retval.append(system)
        except KeyError:
            pass
        return retval

    # create_jobs
    #
    def create_jobs(s):
        if 'tests' not in s.jd:
            s.determine_tests()

        #if 'systems' not in s.jd:
        #    s.determine_systems()
        s.determine_systems()

        #if 'arches' not in s.jd:
        #    s.determine_arches()
        s.determine_arches()

        if Clog.dbg:
            cdebug('tests: [')
            for test in s.jd['tests']:
                cdebug("    '%s'," % test)
            cdebug(']')

            cdebug('systems: [')
            for system in s.jd['systems']:
                cdebug("    '%s'," % system)
            cdebug(']')

            cdebug('arches: [')
            for arch in s.jd['arches']:
                cdebug("    '%s'," % arch)
            cdebug(']')

class RequestHandler(threading.Thread):

    # __init__
    #
    def __init__(s, cmd_q=queue.Queue(), reply_q=queue.Queue(), cfg={}, msgq=None):
        threading.Thread.__init__(s)
        s.cmd_q = cmd_q
        s.reply_q = reply_q
        s.msgq = msgq
        s.alive = threading.Event()
        s.alive.set()
        s.cfg = cfg

    # handle_request
    #
    def handle(s, request):
        center(s.__class__.__name__ + '.handle')
        cinfo('        ---------------------------------------  h a n d l e  ---------------------------------------', 'green')
        cinfo(json.dumps(request, sort_keys=True, indent=4))

        jc = JobsCreator(request)
        jc.create_jobs()

        cleave(s.__class__.__name__ + '.handle')

    # dequeue
    #
    def dequeue(s):
        center(s.__class__.__name__ + '.dequeue')
        try:
            # Queue.get with timeout to allow checking s.alive
            request = s.cmd_q.get(True, 0.1)
            s.handle(request)

        except queue.Empty:
            pass
        cleave(s.__class__.__name__ + '.dequeue')

    # run
    #
    def run(s):
        center(s.__class__.__name__ + '.run')
        while s.alive.isSet():
            s.dequeue()
            sleep(10)
        cleave(s.__class__.__name__ + '.run')


# JobFactory
#
class JobFactory(object):
    '''
    '''

    # __init__
    #
    def __init__(s):
        '''
        '''
        center(s.__class__.__name__ + '.__init__')
        cleave(s.__class__.__name__ + '.__init__')

    # sigterm_handler
    #
    def sigterm_handler(s, signu, frame):
        center(s.__class__.__name__ + '.sigterm_handler')
        raise Exit()
        cleave(s.__class__.__name__ + '.sigterm_handler')

    # sighup_handler
    #
    def sighup_handler(s, signu, frame):
        center(s.__class__.__name__ + '.sighup_handler')
        cleave(s.__class__.__name__ + '.sighup_handler')

    # enqueue
    #
    def enqueue(s, payload):
        center(s.__class__.__name__ + '.enqueue')
        s.rh.cmd_q.put(payload)
        cleave(s.__class__.__name__ + '.enqueue')

    # msgq_handler
    #
    def msgq_handler(s, payload):
        center(s.__class__.__name__ + '.msgq_handler')

        # Based on command line options we support different keys
        #
        if s.args.lkp:
            valid_keys = ['kernel.testing.livekernelpatching.request', 'livepatch.publish']
        elif s.args.dev:
            valid_keys = ['kdev.testing.request', 'kdev.testing.livekernelpatching.request']
        else:
            valid_keys = ['kernel.testing.request', 'kernel.publish', 'kernel.maas.daily', 'kernel-publish.ppa', 'kernel.testing.job']

        # Determine if the key in the current message is on that
        # we are going to process.
        #
        queued = False
        for key in valid_keys:
            if payload['key'].startswith(key):
                s.enqueue(payload)
                queued = True
                break

        if not queued:
            cinfo('ignored: %s' % payload['key'], 'magenta')

        cleave(s.__class__.__name__ + '.msgq_handler')

    # main
    #
    def main(s, args):
        center(s.__class__.__name__ + '.main')
        retval = 0
        s.args = args

        signal.signal(signal.SIGTERM, s.sigterm_handler)
        signal.signal(signal.SIGHUP,  s.sighup_handler)

        try:
            if args.local_msgqueue_port:
                # s.mq = MsgQueue(address='localhost', port=args.local_msgqueue_port)
                mq = MsgQueue(address='localhost', port=9123)
            else:
                mq = MsgQueue()

            s.rh = RequestHandler(msgq=mq)
            s.rh.start()

            if args.lkp:
                queue = 'livepatch-monitor'
                mq.listen(queue, 'livepatch.#', s.msgq_handler)
            elif args.dev:
                queue = 'kdev-publishing-monitor'
                mq.listen(queue, 'kdev.#', s.msgq_handler)
            else:
                # queue = 'kernel-publishing-monitor'
                queue = 'kdev-publishing-monitor'          # FIXME bjf - For development I am using this queue
                mq.listen(queue, 'kernel.#', s.msgq_handler)

            retval = 0

        # Handle the user presses <ctrl-C>.
        #
        except KeyboardInterrupt:
            print("Aborting ...")
            s.rh.alive.clear()

        except Exit:
            print("")
            print("Due to the above error(s), this script is unable to continue and is terminating.")
            print("")
            s.rh.alive.clear()

        cleave(s.__class__.__name__ + '.main (%s)' % retval)
        return retval

if __name__ == '__main__':
    retval = -1

    # Command line argument setup and initial processing
    #
    app_description = '''
    '''
    app_epilog = '''
    '''
    parser = ArgumentParser(description=app_description, epilog=app_epilog, formatter_class=RawDescriptionHelpFormatter)
    parser.add_argument('--debug', action='store_true', default=False, help='')
    parser.add_argument('--info',  action='store_true', default=False, help='')
    parser.add_argument('--lkp',   action='store_true', default=False, help='Handle requests for live kernel patching testing.')
    parser.add_argument('--dev',   action='store_true', default=False, help='Handle development testing requests.')
    parser.add_argument('--local-msgqueue-port',  type=int, default=None,  help='The local port to be used to talk to the Rabbit MQ service.')

    args = parser.parse_args()

    # If logging parameters were set on the command line, handle them
    # here.
    #
    Clog.color = True
    if args.debug:
        log_format = "%(levelname)s - %(message)s"
        basicConfig(level=DEBUG, format=log_format)
        Clog.dbg = True
    elif args.info:
        log_format = "%(message)s"
        basicConfig(level=INFO, format=log_format)
    else:
        log_format = "%(message)s"
        basicConfig(level=WARNING, format=log_format)

    center('__main__')
    try:
        app = JobFactory()
        retval = app.main(args)
    except KeyboardInterrupt:
        pass
    except Exception:
        trace = traceback.format_exc()
        try:
            stderr.write(trace)
        except:
            pass
        logfile = open(path.join('.', 'exceptions.log'), 'a')
        logfile.write('Critical exception in %s' % argv[0])
        logfile.write(trace)
        logfile.write('----------------------------------------\n\n')
        logfile.close()

    cleave('__main__ (%s)' % (retval))
    exit(retval)

# vi:set ts=4 sw=4 expandtab syntax=python:
